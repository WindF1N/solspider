#!/usr/bin/env python3
"""
–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–æ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π –º–µ–∂–¥—É –º–µ—Ç—Ä–∏–∫–∞–º–∏ –∞–≤—Ç–æ—Ä–æ–≤ —Ç–≤–∏—Ç–æ–≤ –∏ —Ç–æ–∫–µ–Ω–∞–º–∏
"""

import pandas as pd
import asyncio
from datetime import datetime, timedelta
import logging
import re
from dotenv import load_dotenv
from database import get_db_manager, Token
from twitter_profile_parser import TwitterProfileParser
from logger_config import setup_logging

# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
load_dotenv()

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
setup_logging()
logger = logging.getLogger(__name__)

class DemoTwitterAnalyzer:
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–æ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä Twitter –∞–≤—Ç–æ—Ä–æ–≤"""
    
    def __init__(self):
        self.db_manager = get_db_manager()
        
    def create_sample_tweets(self, tokens):
        """–°–æ–∑–¥–∞–µ—Ç –ø—Ä–∏–º–µ—Ä—ã –æ–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã—Ö —Ç–≤–∏—Ç–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞"""
        sample_tweets = []
        
        # –°–ø–∏—Å–æ–∫ –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö crypto –∞–∫–∫–∞—É–Ω—Ç–æ–≤ –¥–ª—è —Å–∏–º—É–ª—è—Ü–∏–∏
        crypto_accounts = [
            {"username": "LaunchOnPump", "type": "bot"},
            {"username": "pumpdotfun", "type": "platform"},
            {"username": "solana", "type": "official"},
            {"username": "elonmusk", "type": "influencer"},
            {"username": "cz_binance", "type": "ceo"},
            {"username": "VitalikButerin", "type": "developer"},
            {"username": "SBF_FTX", "type": "ceo"},
            {"username": "justinsuntron", "type": "founder"},
            {"username": "APompliano", "type": "analyst"},
            {"username": "WClementeIII", "type": "analyst"}
        ]
        
        # –®–∞–±–ª–æ–Ω—ã —Ç–≤–∏—Ç–æ–≤
        tweet_templates = [
            "üöÄ New gem found! Check out {symbol} at {contract} - this could be huge! #crypto #solana",
            "RT @pumpdotfun: {symbol} just launched! Contract: {contract} üî•",
            "üìà {symbol} is pumping! Contract address: {contract} - get in early!",
            "üíé Found another gem: {symbol} ({contract}) - thank me later üöÄ",
            "üéØ New token alert: {symbol} - {contract} - looks promising!",
            "Breaking: {symbol} contract {contract} shows massive potential üìä",
            "Alpha alert üö® {symbol} ({contract}) is about to moon! DYOR",
            "Just ape'd into {symbol} - contract {contract} looks solid üí™",
            "Technical analysis on {symbol} ({contract}) looking bullish üìà",
            "Community is growing fast around {symbol} - {contract} üöÄ"
        ]
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ç–≤–∏—Ç—ã –¥–ª—è —Ç–æ–ø-20 —Ç–æ–∫–µ–Ω–æ–≤
        for i, token in enumerate(tokens[:10]):  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º 10 —Ç–æ–∫–µ–Ω–∞–º–∏ –¥–ª—è –¥–µ–º–æ
            # –°–ª—É—á–∞–π–Ω–æ –≤—ã–±–∏—Ä–∞–µ–º –∞–≤—Ç–æ—Ä–∞ –∏ —à–∞–±–ª–æ–Ω
            author = crypto_accounts[i % len(crypto_accounts)]
            template = tweet_templates[i % len(tweet_templates)]
            
            tweet_text = template.format(
                symbol=token.symbol,
                contract=token.mint
            )
            
            # –°–∏–º—É–ª–∏—Ä—É–µ–º –≤—Ä–µ–º—è —Å–æ–∑–¥–∞–Ω–∏—è —Ç–≤–∏—Ç–∞ (–æ—Ç 1 –¥–æ 24 —á–∞—Å–æ–≤ –ø–æ—Å–ª–µ —Å–æ–∑–¥–∞–Ω–∏—è —Ç–æ–∫–µ–Ω–∞)
            hours_after = (i % 24) + 1
            tweet_time = token.created_at + timedelta(hours=hours_after, minutes=i*3)
            
            sample_tweets.append({
                'token': token,
                'author_username': author['username'],
                'author_type': author['type'],
                'tweet_text': tweet_text,
                'tweet_created_at': tweet_time,
                'discovered_at': datetime.utcnow()
            })
        
        return sample_tweets
    
    async def analyze_sample_tweets_with_authors(self):
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ø—Ä–∏–º–µ—Ä—ã —Ç–≤–∏—Ç–æ–≤ —Å –∑–∞–≥—Ä—É–∑–∫–æ–π —Ä–µ–∞–ª—å–Ω—ã—Ö –ø—Ä–æ—Ñ–∏–ª–µ–π –∞–≤—Ç–æ—Ä–æ–≤"""
        try:
            session = self.db_manager.Session()
            
            logger.info("üîç –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–æ–∫–µ–Ω—ã —Å –Ω–∞–π–¥–µ–Ω–Ω—ã–º–∏ –∫–æ–Ω—Ç—Ä–∞–∫—Ç–∞–º–∏ –¥–ª—è –¥–µ–º–æ...")
            
            # –ü–æ–ª—É—á–∞–µ–º —Ç–æ–ø-20 —Ç–æ–∫–µ–Ω–æ–≤ —Å –∫–æ–Ω—Ç—Ä–∞–∫—Ç–Ω—ã–º–∏ —Ç–≤–∏—Ç–∞–º–∏
            tokens = session.query(Token).filter(
                Token.twitter_contract_tweets > 0,
                Token.mint.isnot(None),
                Token.symbol.isnot(None)
            ).order_by(Token.twitter_contract_tweets.desc()).limit(20).all()
            
            logger.info(f"üìä –ù–∞–π–¥–µ–Ω–æ {len(tokens)} —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
            
            if not tokens:
                logger.error("‚ùå –ù–µ—Ç —Ç–æ–∫–µ–Ω–æ–≤ —Å –∫–æ–Ω—Ç—Ä–∞–∫—Ç–Ω—ã–º–∏ —Ç–≤–∏—Ç–∞–º–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
                return []
            
            # –°–æ–∑–¥–∞–µ–º –ø—Ä–∏–º–µ—Ä—ã —Ç–≤–∏—Ç–æ–≤
            sample_tweets = self.create_sample_tweets(tokens)
            logger.info(f"üì± –°–æ–∑–¥–∞–Ω–æ {len(sample_tweets)} –ø—Ä–∏–º–µ—Ä–æ–≤ —Ç–≤–∏—Ç–æ–≤")
            
            results = []
            unique_authors = set()
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø—Ä–æ—Ñ–∏–ª–∏ –∞–≤—Ç–æ—Ä–æ–≤
            async with TwitterProfileParser() as profile_parser:
                for i, tweet_sample in enumerate(sample_tweets, 1):
                    logger.info(f"üë§ –ê–Ω–∞–ª–∏–∑ –∞–≤—Ç–æ—Ä–∞ {i}/{len(sample_tweets)}: @{tweet_sample['author_username']}")
                    
                    author_username = tweet_sample['author_username']
                    
                    # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø—Ä–æ—Ñ–∏–ª—å –∞–≤—Ç–æ—Ä–∞ –µ—Å–ª–∏ –µ—â–µ –Ω–µ –∑–∞–≥—Ä—É–∂–∞–ª–∏
                    if author_username not in unique_authors:
                        profile_data = await profile_parser.get_profile(author_username)
                        
                        if profile_data:
                            unique_authors.add(author_username)
                            logger.info(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω –ø—Ä–æ—Ñ–∏–ª—å @{author_username}: "
                                       f"{profile_data['followers_count']:,} –ø–æ–¥–ø–∏—Å—á–∏–∫–æ–≤")
                            
                            # –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                            result = {
                                'token': tweet_sample['token'],
                                'tweet_data': tweet_sample,
                                'author_data': profile_data,
                                'author_type': tweet_sample['author_type']
                            }
                            results.append(result)
                        else:
                            logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –ø—Ä–æ—Ñ–∏–ª—å @{author_username}")
                    
                    # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
                    await asyncio.sleep(2)
            
            session.close()
            return results
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞: {e}")
            return []
    
    def categorize_author_influence(self, author_data):
        """–ö–∞—Ç–µ–≥–æ—Ä–∏–∑–∏—Ä—É–µ—Ç –≤–ª–∏—è–Ω–∏–µ –∞–≤—Ç–æ—Ä–∞"""
        followers = author_data['followers_count']
        is_verified = author_data['is_verified']
        
        if is_verified and followers > 1000000:
            return "–ú–µ–≥–∞-–∏–Ω—Ñ–ª—é–µ–Ω—Å–µ—Ä"
        elif is_verified and followers > 100000:
            return "–ú–∞–∫—Ä–æ-–∏–Ω—Ñ–ª—é–µ–Ω—Å–µ—Ä"
        elif followers > 100000:
            return "–ë–æ–ª—å—à–æ–π –∏–Ω—Ñ–ª—é–µ–Ω—Å–µ—Ä"
        elif followers > 10000:
            return "–°—Ä–µ–¥–Ω–∏–π –∏–Ω—Ñ–ª—é–µ–Ω—Å–µ—Ä"
        elif followers > 1000:
            return "–ú–∏–∫—Ä–æ-–∏–Ω—Ñ–ª—é–µ–Ω—Å–µ—Ä"
        elif followers > 100:
            return "–ù–∞–Ω–æ-–∏–Ω—Ñ–ª—é–µ–Ω—Å–µ—Ä"
        else:
            return "–û–±—ã—á–Ω—ã–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å"
    
    def estimate_influence_potential(self, author_data):
        """–û—Ü–µ–Ω–∏–≤–∞–µ—Ç –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª –≤–ª–∏—è–Ω–∏—è –∞–≤—Ç–æ—Ä–∞"""
        followers = author_data['followers_count']
        tweets = author_data['tweets_count']
        is_verified = author_data['is_verified']
        
        # –ü—Ä–æ—Å—Ç–∞—è —Å–∏—Å—Ç–µ–º–∞ –æ—Ü–µ–Ω–∫–∏
        score = 0
        
        # –ü–æ–¥–ø–∏—Å—á–∏–∫–∏
        if followers > 1000000:
            score += 100
        elif followers > 100000:
            score += 80
        elif followers > 10000:
            score += 60
        elif followers > 1000:
            score += 40
        elif followers > 100:
            score += 20
        
        # –í–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏—è
        if is_verified:
            score += 30
        
        # –ê–∫—Ç–∏–≤–Ω–æ—Å—Ç—å
        if tweets > 10000:
            score += 20
        elif tweets > 1000:
            score += 10
        
        # –ö–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏—è
        if score >= 120:
            return "–ö—Ä–∏—Ç–∏—á–µ—Å–∫–æ–µ"
        elif score >= 100:
            return "–û—á–µ–Ω—å –≤—ã—Å–æ–∫–æ–µ"
        elif score >= 80:
            return "–í—ã—Å–æ–∫–æ–µ"
        elif score >= 60:
            return "–°—Ä–µ–¥–Ω–µ–µ"
        elif score >= 40:
            return "–ù–∏–∑–∫–æ–µ"
        else:
            return "–ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ"
    
    def create_demo_analysis_excel(self, results):
        """–°–æ–∑–¥–∞–µ—Ç –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–æ–Ω–Ω—ã–π Excel –æ—Ç—á–µ—Ç"""
        try:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f"demo_twitter_correlation_analysis_{timestamp}.xlsx"
            
            # 1. –û—Å–Ω–æ–≤–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ –∞–Ω–∞–ª–∏–∑–∞
            main_analysis = []
            
            # 2. –°–≤–æ–¥–∫–∞ –ø–æ –∞–≤—Ç–æ—Ä–∞–º
            author_summary = []
            
            # 3. –ê–Ω–∞–ª–∏–∑ –ø–æ —Ç–∏–ø–∞–º –∞–≤—Ç–æ—Ä–æ–≤
            author_type_analysis = []
            
            # 4. –ü–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏
            correlation_insights = []
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            for result in results:
                token = result['token']
                tweet_data = result['tweet_data']
                author_data = result['author_data']
                author_type = result['author_type']
                
                # –û—Å–Ω–æ–≤–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞
                main_row = {
                    '–°–∏–º–≤–æ–ª —Ç–æ–∫–µ–Ω–∞': token.symbol,
                    '–ù–∞–∑–≤–∞–Ω–∏–µ —Ç–æ–∫–µ–Ω–∞': token.name or 'N/A',
                    'Market Cap': f"${token.market_cap:,.0f}" if token.market_cap else 'N/A',
                    '–í–æ–∑—Ä–∞—Å—Ç —Ç–æ–∫–µ–Ω–∞ (—á)': f"{(datetime.utcnow() - token.created_at).total_seconds() / 3600:.1f}",
                    '–ê–¥—Ä–µ—Å –∫–æ–Ω—Ç—Ä–∞–∫—Ç–∞': token.mint,
                    
                    # –î–∞–Ω–Ω—ã–µ —Ç–≤–∏—Ç–∞
                    '–¢–µ–∫—Å—Ç —Ç–≤–∏—Ç–∞': tweet_data['tweet_text'][:150] + '...' if len(tweet_data['tweet_text']) > 150 else tweet_data['tweet_text'],
                    '–í—Ä–µ–º—è –¥–æ —Ç–≤–∏—Ç–∞ (—á)': f"{(tweet_data['tweet_created_at'] - token.created_at).total_seconds() / 3600:.1f}",
                    
                    # –î–∞–Ω–Ω—ã–µ –∞–≤—Ç–æ—Ä–∞
                    '–ê–≤—Ç–æ—Ä': f"@{author_data['username']}",
                    '–ò–º—è –∞–≤—Ç–æ—Ä–∞': author_data['display_name'] or 'N/A',
                    '–¢–∏–ø –∞–≤—Ç–æ—Ä–∞': author_type.title(),
                    '–ü–æ–¥–ø–∏—Å—á–∏–∫–∏': f"{author_data['followers_count']:,}",
                    '–¢–≤–∏—Ç—ã': f"{author_data['tweets_count']:,}",
                    '–ü–æ–¥–ø–∏—Å–∫–∏': f"{author_data['following_count']:,}",
                    '–õ–∞–π–∫–∏': f"{author_data['likes_count']:,}",
                    '–í–µ—Ä–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω': '–î–∞' if author_data['is_verified'] else '–ù–µ—Ç',
                    '–î–∞—Ç–∞ —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏': author_data['join_date'] or 'N/A',
                    
                    # –ê–Ω–∞–ª–∏–∑ –≤–ª–∏—è–Ω–∏—è
                    '–ö–∞—Ç–µ–≥–æ—Ä–∏—è –≤–ª–∏—è–Ω–∏—è': self.categorize_author_influence(author_data),
                    '–ü–æ—Ç–µ–Ω—Ü–∏–∞–ª –≤–ª–∏—è–Ω–∏—è': self.estimate_influence_potential(author_data),
                    'Engagement Rate': f"{(author_data['likes_count'] / max(author_data['tweets_count'], 1)):.2f}",
                    'Follow Ratio': f"{(author_data['followers_count'] / max(author_data['following_count'], 1)):.1f}",
                    
                    # –°—Å—ã–ª–∫–∏
                    '–ü—Ä–æ—Ñ–∏–ª—å Twitter': f"https://nitter.tiekoetter.com/{author_data['username']}",
                    'DexScreener': f"https://dexscreener.com/solana/{token.mint}",
                    'Pump.fun': f"https://pump.fun/{token.mint}"
                }
                main_analysis.append(main_row)
            
            # –°–≤–æ–¥–∫–∞ –ø–æ –∞–≤—Ç–æ—Ä–∞–º
            unique_authors = {}
            for result in results:
                author_data = result['author_data']
                if author_data['username'] not in unique_authors:
                    unique_authors[author_data['username']] = {
                        'data': author_data,
                        'type': result['author_type'],
                        'mentioned_tokens': 1
                    }
                else:
                    unique_authors[author_data['username']]['mentioned_tokens'] += 1
            
            for username, info in unique_authors.items():
                author_data = info['data']
                author_row = {
                    'Username': f"@{username}",
                    '–û—Ç–æ–±—Ä–∞–∂–∞–µ–º–æ–µ –∏–º—è': author_data['display_name'] or 'N/A',
                    '–¢–∏–ø –∞–∫–∫–∞—É–Ω—Ç–∞': info['type'].title(),
                    '–ü–æ–¥–ø–∏—Å—á–∏–∫–∏': author_data['followers_count'],
                    '–¢–≤–∏—Ç—ã': author_data['tweets_count'],
                    '–ü–æ–¥–ø–∏—Å–∫–∏': author_data['following_count'],
                    '–õ–∞–π–∫–∏': author_data['likes_count'],
                    '–í–µ—Ä–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω': '–î–∞' if author_data['is_verified'] else '–ù–µ—Ç',
                    '–î–∞—Ç–∞ —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏': author_data['join_date'] or 'N/A',
                    '–£–ø–æ–º—è–Ω—É—Ç–æ —Ç–æ–∫–µ–Ω–æ–≤': info['mentioned_tokens'],
                    '–ö–∞—Ç–µ–≥–æ—Ä–∏—è –≤–ª–∏—è–Ω–∏—è': self.categorize_author_influence(author_data),
                    '–ü–æ—Ç–µ–Ω—Ü–∏–∞–ª –≤–ª–∏—è–Ω–∏—è': self.estimate_influence_potential(author_data),
                    '–ü—Ä–æ—Ñ–∏–ª—å': f"https://nitter.tiekoetter.com/{username}"
                }
                author_summary.append(author_row)
            
            # –ê–Ω–∞–ª–∏–∑ –ø–æ —Ç–∏–ø–∞–º –∞–≤—Ç–æ—Ä–æ–≤
            type_stats = {}
            for result in results:
                author_type = result['author_type']
                author_data = result['author_data']
                
                if author_type not in type_stats:
                    type_stats[author_type] = {
                        'count': 0,
                        'total_followers': 0,
                        'verified_count': 0,
                        'usernames': []
                    }
                
                type_stats[author_type]['count'] += 1
                type_stats[author_type]['total_followers'] += author_data['followers_count']
                if author_data['is_verified']:
                    type_stats[author_type]['verified_count'] += 1
                type_stats[author_type]['usernames'].append(f"@{author_data['username']}")
            
            for author_type, stats in type_stats.items():
                avg_followers = stats['total_followers'] / stats['count'] if stats['count'] > 0 else 0
                type_row = {
                    '–¢–∏–ø –∞–≤—Ç–æ—Ä–∞': author_type.title(),
                    '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ': stats['count'],
                    '–°—Ä–µ–¥–Ω–∏–µ –ø–æ–¥–ø–∏—Å—á–∏–∫–∏': f"{avg_followers:,.0f}",
                    '–í–µ—Ä–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö': stats['verified_count'],
                    '% –≤–µ—Ä–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö': f"{(stats['verified_count'] / stats['count'] * 100):.1f}%" if stats['count'] > 0 else '0%',
                    '–ü—Ä–∏–º–µ—Ä—ã –∞–∫–∫–∞—É–Ω—Ç–æ–≤': ', '.join(stats['usernames'][:3])
                }
                author_type_analysis.append(type_row)
            
            # –ü–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ –∏ –∏–Ω—Å–∞–π—Ç—ã
            correlation_insights = [
                {
                    '–ò–Ω—Å–∞–π—Ç': '–í–ª–∏—è–Ω–∏–µ —Ç–∏–ø–∞ –∞–≤—Ç–æ—Ä–∞',
                    '–û–ø–∏—Å–∞–Ω–∏–µ': '–û—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–µ –∞–∫–∫–∞—É–Ω—Ç—ã –∏ CEO –∏–º–µ—é—Ç –Ω–∞–∏–±–æ–ª—å—à–µ–µ –≤–ª–∏—è–Ω–∏–µ –Ω–∞ –¥–≤–∏–∂–µ–Ω–∏–µ —Ç–æ–∫–µ–Ω–æ–≤',
                    '–ü–æ—Ç–µ–Ω—Ü–∏–∞–ª': '–í—ã—Å–æ–∫–∏–π',
                    '–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è': '–ú–æ–Ω–∏—Ç–æ—Ä–∏—Ç—å —Ç–≤–∏—Ç—ã –≤–µ—Ä–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∞–∫–∫–∞—É–Ω—Ç–æ–≤ —Å >100k –ø–æ–¥–ø–∏—Å—á–∏–∫–æ–≤'
                },
                {
                    '–ò–Ω—Å–∞–π—Ç': '–í—Ä–µ–º–µ–Ω–Ω–æ–π —Ñ–∞–∫—Ç–æ—Ä',
                    '–û–ø–∏—Å–∞–Ω–∏–µ': '–¢–≤–∏—Ç—ã –≤ –ø–µ—Ä–≤—ã–µ 6 —á–∞—Å–æ–≤ –ø–æ—Å–ª–µ —Å–æ–∑–¥–∞–Ω–∏—è —Ç–æ–∫–µ–Ω–∞ –∏–º–µ—é—Ç –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –≤–ª–∏—è–Ω–∏–µ',
                    '–ü–æ—Ç–µ–Ω—Ü–∏–∞–ª': '–û—á–µ–Ω—å –≤—ã—Å–æ–∫–∏–π',
                    '–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è': '–ü—Ä–∏–æ—Ä–∏—Ç–µ–∑–∏—Ä–æ–≤–∞—Ç—å –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –Ω–æ–≤—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤ (< 6 —á–∞—Å–æ–≤)'
                },
                {
                    '–ò–Ω—Å–∞–π—Ç': 'Engagement –∫–∞—á–µ—Å—Ç–≤–æ',
                    '–û–ø–∏—Å–∞–Ω–∏–µ': '–ê–≤—Ç–æ—Ä—ã —Å –≤—ã—Å–æ–∫–∏–º engagement rate (–ª–∞–π–∫–∏/—Ç–≤–∏—Ç—ã) –¥–∞—é—Ç –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ —Å–∏–≥–Ω–∞–ª—ã',
                    '–ü–æ—Ç–µ–Ω—Ü–∏–∞–ª': '–°—Ä–µ–¥–Ω–∏–π',
                    '–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è': '–§–∏–ª—å—Ç—Ä–æ–≤–∞—Ç—å –∞–≤—Ç–æ—Ä–æ–≤ –ø–æ –∫–∞—á–µ—Å—Ç–≤—É engagement (>2.0 ratio)'
                },
                {
                    '–ò–Ω—Å–∞–π—Ç': '–í–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏—è –≤–∞–∂–Ω–∞',
                    '–û–ø–∏—Å–∞–Ω–∏–µ': '–í–µ—Ä–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∞–∫–∫–∞—É–Ω—Ç—ã —Å–æ–∑–¥–∞—é—Ç –±–æ–ª–µ–µ —Å–∏–ª—å–Ω—ã–µ –¥–≤–∏–∂–µ–Ω–∏—è —Ü–µ–Ω—ã',
                    '–ü–æ—Ç–µ–Ω—Ü–∏–∞–ª': '–í—ã—Å–æ–∫–∏–π',
                    '–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è': '–û—Ç–¥–∞–≤–∞—Ç—å –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç —Ç–≤–∏—Ç–∞–º –æ—Ç –≤–µ—Ä–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∞–∫–∫–∞—É–Ω—Ç–æ–≤'
                }
            ]
            
            # –°–æ–∑–¥–∞–µ–º DataFrame'—ã
            main_df = pd.DataFrame(main_analysis)
            author_df = pd.DataFrame(author_summary)
            type_df = pd.DataFrame(author_type_analysis)
            insights_df = pd.DataFrame(correlation_insights)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ Excel
            with pd.ExcelWriter(filename, engine='openpyxl') as writer:
                main_df.to_excel(writer, sheet_name='–û—Å–Ω–æ–≤–Ω–æ–π –∞–Ω–∞–ª–∏–∑', index=False)
                author_df.to_excel(writer, sheet_name='–ê–≤—Ç–æ—Ä—ã', index=False)
                type_df.to_excel(writer, sheet_name='–¢–∏–ø—ã –∞–≤—Ç–æ—Ä–æ–≤', index=False)
                insights_df.to_excel(writer, sheet_name='–ò–Ω—Å–∞–π—Ç—ã', index=False)
                
                # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
                stats_data = [
                    {'–ú–µ—Ç—Ä–∏–∫–∞': '–í—Å–µ–≥–æ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤', '–ó–Ω–∞—á–µ–Ω–∏–µ': len(set(r['token'].id for r in results))},
                    {'–ú–µ—Ç—Ä–∏–∫–∞': '–í—Å–µ–≥–æ —Ç–≤–∏—Ç–æ–≤ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ', '–ó–Ω–∞—á–µ–Ω–∏–µ': len(results)},
                    {'–ú–µ—Ç—Ä–∏–∫–∞': '–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∞–≤—Ç–æ—Ä–æ–≤', '–ó–Ω–∞—á–µ–Ω–∏–µ': len(unique_authors)},
                    {'–ú–µ—Ç—Ä–∏–∫–∞': '–í–µ—Ä–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∞–≤—Ç–æ—Ä–æ–≤', '–ó–Ω–∞—á–µ–Ω–∏–µ': sum(1 for r in results if r['author_data']['is_verified'])},
                    {'–ú–µ—Ç—Ä–∏–∫–∞': '–°—Ä–µ–¥–Ω–∏–µ –ø–æ–¥–ø–∏—Å—á–∏–∫–∏', '–ó–Ω–∞—á–µ–Ω–∏–µ': f"{sum(r['author_data']['followers_count'] for r in results) / len(results):,.0f}"},
                    {'–ú–µ—Ç—Ä–∏–∫–∞': '–ú–∞–∫—Å–∏–º—É–º –ø–æ–¥–ø–∏—Å—á–∏–∫–æ–≤', '–ó–Ω–∞—á–µ–Ω–∏–µ': f"{max(r['author_data']['followers_count'] for r in results):,}"},
                    {'–ú–µ—Ç—Ä–∏–∫–∞': '–î–∞—Ç–∞ –∞–Ω–∞–ª–∏–∑–∞', '–ó–Ω–∞—á–µ–Ω–∏–µ': datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
                ]
                
                stats_df = pd.DataFrame(stats_data)
                stats_df.to_excel(writer, sheet_name='–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞', index=False)
                
                # –ê–≤—Ç–æ–ø–æ–¥–≥–æ–Ω–∫–∞ —à–∏—Ä–∏–Ω—ã –∫–æ–ª–æ–Ω–æ–∫
                for sheet_name in writer.sheets:
                    worksheet = writer.sheets[sheet_name]
                    for column in worksheet.columns:
                        max_length = 0
                        column_letter = column[0].column_letter
                        for cell in column:
                            try:
                                if len(str(cell.value)) > max_length:
                                    max_length = len(str(cell.value))
                            except:
                                pass
                        adjusted_width = min(max_length + 2, 50)
                        worksheet.column_dimensions[column_letter].width = adjusted_width
                    
                    worksheet.freeze_panes = 'A2'
            
            logger.info(f"‚úÖ –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–æ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ {filename}")
            return filename
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è Excel: {e}")
            return None

async def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–µ–º–æ-–∞–Ω–∞–ª–∏–∑–∞"""
    logger.info("üöÄ –ó–∞–ø—É—Å–∫ –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–æ–Ω–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π Twitter –∞–≤—Ç–æ—Ä–æ–≤")
    
    analyzer = DemoTwitterAnalyzer()
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç–≤–∏—Ç—ã —Å —Ä–µ–∞–ª—å–Ω—ã–º–∏ –ø—Ä–æ—Ñ–∏–ª—è–º–∏ –∞–≤—Ç–æ—Ä–æ–≤
    results = await analyzer.analyze_sample_tweets_with_authors()
    
    if not results:
        logger.error("‚ùå –ù–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
        return
    
    logger.info(f"üìä –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ {len(results)} —Ç–≤–∏—Ç–æ–≤ —Å –ø—Ä–æ—Ñ–∏–ª—è–º–∏ –∞–≤—Ç–æ—Ä–æ–≤")
    
    # –°–æ–∑–¥–∞–µ–º –æ—Ç—á–µ—Ç
    filename = analyzer.create_demo_analysis_excel(results)
    
    if filename:
        logger.info(f"üìà –î–ï–ú–û–ù–°–¢–†–ê–¶–ò–û–ù–ù–´–ô –ê–ù–ê–õ–ò–ó –ö–û–†–†–ï–õ–Ø–¶–ò–ô:")
        logger.info(f"  ‚Ä¢ –§–∞–π–ª: {filename}")
        logger.info(f"  ‚Ä¢ –¢–≤–∏—Ç–æ–≤: {len(results)}")
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ç–∏–ø–∞–º –∞–≤—Ç–æ—Ä–æ–≤
        type_stats = {}
        total_followers = 0
        verified_count = 0
        
        for result in results:
            author_type = result['author_type']
            author_data = result['author_data']
            
            if author_type not in type_stats:
                type_stats[author_type] = 0
            type_stats[author_type] += 1
            
            total_followers += author_data['followers_count']
            if author_data['is_verified']:
                verified_count += 1
        
        logger.info(f"  ‚Ä¢ –°—Ä–µ–¥–Ω–∏–µ –ø–æ–¥–ø–∏—Å—á–∏–∫–∏: {total_followers / len(results):,.0f}")
        logger.info(f"  ‚Ä¢ –í–µ—Ä–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö: {verified_count}/{len(results)}")
        logger.info(f"  ‚Ä¢ –¢–∏–ø—ã –∞–≤—Ç–æ—Ä–æ–≤: {dict(type_stats)}")
    
    logger.info("‚úÖ –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–æ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω!")

if __name__ == "__main__":
    asyncio.run(main()) 