#!/usr/bin/env python3
"""
–ê–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö –ø–æ–≤–µ–¥–µ–Ω–∏—è —Ç–æ–∫–µ–Ω–æ–≤
–ò—â–µ—Ç –ø–∞—Ç—Ç–µ—Ä–Ω—ã volume bot marketing —Å—Ä–µ–¥–∏ —Å–æ–±—Ä–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
"""

import json
import os
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
from datetime import datetime
import numpy as np
from typing import Dict, List, Tuple
import logging

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ matplotlib –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–∞
plt.rcParams['font.size'] = 10
plt.style.use('seaborn-v0_8')

class TokenBehaviorAnalyzer:
    """–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –ø–æ–≤–µ–¥–µ–Ω–∏—è —Ç–æ–∫–µ–Ω–æ–≤"""
    
    def __init__(self, data_dir: str = "token_behavior_data"):
        self.data_dir = Path(data_dir)
        self.analysis_dir = Path("behavior_analysis")
        self.analysis_dir.mkdir(exist_ok=True)
        
    def load_token_data(self, token_address: str) -> pd.DataFrame:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –≤—Å–µ –¥–∞–Ω–Ω—ã–µ –ø–æ —Ç–æ–∫–µ–Ω—É"""
        token_dir = self.data_dir / token_address
        
        if not token_dir.exists():
            logger.warning(f"‚ö†Ô∏è –ü–∞–ø–∫–∞ —Ç–æ–∫–µ–Ω–∞ {token_address[:8]}... –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
            return pd.DataFrame()
        
        data_files = list(token_dir.glob("token_data_*.json"))
        
        if not data_files:
            logger.warning(f"‚ö†Ô∏è –§–∞–π–ª—ã –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ç–æ–∫–µ–Ω–∞ {token_address[:8]}... –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
            return pd.DataFrame()
        
        all_data = []
        
        for file_path in sorted(data_files):
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    all_data.append(data)
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ {file_path}: {e}")
        
        if not all_data:
            return pd.DataFrame()
        
        # –°–æ–∑–¥–∞–µ–º DataFrame
        df = pd.DataFrame(all_data)
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º timestamp –≤ datetime
        if 'timestamp' in df.columns:
            df['timestamp'] = pd.to_datetime(df['timestamp'])
            df = df.sort_values('timestamp').reset_index(drop=True)
        
        logger.info(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df)} –∑–∞–ø–∏—Å–µ–π –¥–ª—è —Ç–æ–∫–µ–Ω–∞ {token_address[:8]}...")
        return df
    
    def detect_volume_bot_patterns(self, df: pd.DataFrame) -> Dict:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –ø–∞—Ç—Ç–µ—Ä–Ω—ã volume bot marketing"""
        if df.empty:
            return {}
        
        patterns = {
            'suspicious_bundler_spikes': [],
            'coordinated_activity': [],
            'whale_concentration': [],
            'rapid_holder_changes': [],
            'liquidity_manipulation': []
        }
        
        # 1. –ê–Ω–∞–ª–∏–∑ –±–∞–Ω–¥–ª–µ—Ä–æ–≤
        if 'bundlers_percentage' in df.columns:
            bundler_values = df['bundlers_percentage'].fillna(0)
            
            # –ü–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã–µ —Å–∫–∞—á–∫–∏ –±–∞–Ω–¥–ª–µ—Ä–æ–≤
            bundler_spikes = []
            for i in range(1, len(bundler_values)):
                if bundler_values.iloc[i] - bundler_values.iloc[i-1] > 15:  # –°–∫–∞—á–æ–∫ > 15%
                    bundler_spikes.append({
                        'timestamp': df.iloc[i]['timestamp'],
                        'jump': bundler_values.iloc[i] - bundler_values.iloc[i-1],
                        'value_before': bundler_values.iloc[i-1],
                        'value_after': bundler_values.iloc[i]
                    })
            
            patterns['suspicious_bundler_spikes'] = bundler_spikes
        
        # 2. –ê–Ω–∞–ª–∏–∑ —Ö–æ–ª–¥–µ—Ä–æ–≤
        if 'holders_count' in df.columns:
            holders = df['holders_count'].fillna(0)
            
            # –ë—ã—Å—Ç—Ä—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Ö–æ–ª–¥–µ—Ä–æ–≤
            rapid_changes = []
            for i in range(1, len(holders)):
                if abs(holders.iloc[i] - holders.iloc[i-1]) > 50:  # –ò–∑–º–µ–Ω–µ–Ω–∏–µ > 50 —Ö–æ–ª–¥–µ—Ä–æ–≤ –∑–∞ –∏–Ω—Ç–µ—Ä–≤–∞–ª
                    rapid_changes.append({
                        'timestamp': df.iloc[i]['timestamp'],
                        'change': holders.iloc[i] - holders.iloc[i-1],
                        'holders_before': holders.iloc[i-1],
                        'holders_after': holders.iloc[i]
                    })
            
            patterns['rapid_holder_changes'] = rapid_changes
        
        # 3. –ê–Ω–∞–ª–∏–∑ –ª–∏–∫–≤–∏–¥–Ω–æ—Å—Ç–∏ (SOL)
        if 'liquidity_sol' in df.columns:
            liquidity = df['liquidity_sol'].fillna(0)
            
            # –ü–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã–µ –º–∞–Ω–∏–ø—É–ª—è—Ü–∏–∏ —Å –ª–∏–∫–≤–∏–¥–Ω–æ—Å—Ç—å—é
            liq_changes = []
            for i in range(1, len(liquidity)):
                if liquidity.iloc[i-1] > 0:  # –ò–∑–±–µ–≥–∞–µ–º –¥–µ–ª–µ–Ω–∏—è –Ω–∞ 0
                    pct_change = abs(liquidity.iloc[i] - liquidity.iloc[i-1]) / liquidity.iloc[i-1] * 100
                    if pct_change > 200:  # –ò–∑–º–µ–Ω–µ–Ω–∏–µ > 200%
                        liq_changes.append({
                            'timestamp': df.iloc[i]['timestamp'],
                            'pct_change': pct_change,
                            'liquidity_before': liquidity.iloc[i-1],
                            'liquidity_after': liquidity.iloc[i]
                        })
            
            patterns['liquidity_manipulation'] = liq_changes
        
        # 4. –ê–Ω–∞–ª–∏–∑ —Ç–æ–ø —Ö–æ–ª–¥–µ—Ä–æ–≤ (–∫–æ–Ω—Ü–µ–Ω—Ç—Ä–∞—Ü–∏—è)
        if 'top10_holders_percent' in df.columns:
            top10_values = df['top10_holders_percent'].fillna(0)
            
            for i, row in df.iterrows():
                top10_concentration = row['top10_holders_percent']
                if top10_concentration > 60:  # –¢–æ–ø-10 —Ö–æ–ª–¥–µ—Ä–æ–≤ > 60%
                    patterns['whale_concentration'].append({
                        'timestamp': row['timestamp'],
                        'top10_concentration': top10_concentration
                    })
        
        # 5. –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ—Ü–µ–Ω—Ç–∞ –±–æ—Ç–æ–≤
        if 'bot_percentage' in df.columns:
            bot_values = df['bot_percentage'].fillna(0)
            
            for i, row in df.iterrows():
                bot_pct = row['bot_percentage']
                if bot_pct > 60:  # –ë–æ—Ç–æ–≤ > 60%
                    patterns['coordinated_activity'].append({
                        'timestamp': row['timestamp'],
                        'bot_percentage': bot_pct,
                        'bot_users_count': row.get('bot_users_count', 0),
                        'holders_count': row.get('holders_count', 0)
                    })
        
        return patterns
    
    def calculate_risk_score(self, patterns: Dict, df: pd.DataFrame) -> float:
        """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –æ–±—â–∏–π —Ä–∏—Å–∫-—Å–∫–æ—Ä —Ç–æ–∫–µ–Ω–∞"""
        score = 0
        
        # –ë–∞–Ω–¥–ª–µ—Ä—ã
        if patterns['suspicious_bundler_spikes']:
            score += len(patterns['suspicious_bundler_spikes']) * 20
        
        # –ë—ã—Å—Ç—Ä—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è —Ö–æ–ª–¥–µ—Ä–æ–≤
        if patterns['rapid_holder_changes']:
            score += len(patterns['rapid_holder_changes']) * 10
        
        # –ú–∞–Ω–∏–ø—É–ª—è—Ü–∏–∏ —Å –ª–∏–∫–≤–∏–¥–Ω–æ—Å—Ç—å—é
        if patterns['liquidity_manipulation']:
            score += len(patterns['liquidity_manipulation']) * 15
        
        # –ö–æ–Ω—Ü–µ–Ω—Ç—Ä–∞—Ü–∏—è –∫–∏—Ç–æ–≤
        if patterns['whale_concentration']:
            score += len(patterns['whale_concentration']) * 25
        
        # –ö–æ–æ—Ä–¥–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –±–æ—Ç–æ–≤
        if patterns['coordinated_activity']:
            score += len(patterns['coordinated_activity']) * 30
        
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∫—Ä–∏—Ç–µ—Ä–∏–∏
        if not df.empty:
            # –í—ã—Å–æ–∫–∏–π –ø–æ—Å—Ç–æ—è–Ω–Ω—ã–π –ø—Ä–æ—Ü–µ–Ω—Ç –±–∞–Ω–¥–ª–µ—Ä–æ–≤
            if 'bundlers_percentage' in df.columns:
                avg_bundlers = df['bundlers_percentage'].fillna(0).mean()
                if avg_bundlers > 20:
                    score += 40  # –ü–æ–≤—ã—à–µ–Ω–Ω—ã–π –≤–µ—Å –¥–ª—è bundlers
                elif avg_bundlers > 10:
                    score += 25
                elif avg_bundlers > 5:
                    score += 15
            
            # –í—ã—Å–æ–∫–∏–π –ø—Ä–æ—Ü–µ–Ω—Ç –∏–Ω—Å–∞–π–¥–µ—Ä–æ–≤
            if 'insiders_percentage' in df.columns:
                avg_insiders = df['insiders_percentage'].fillna(0).mean()
                if avg_insiders > 15:
                    score += 30
                elif avg_insiders > 8:
                    score += 20
            
            # –í—ã—Å–æ–∫–∏–π –ø—Ä–æ—Ü–µ–Ω—Ç –±–æ—Ç–æ–≤
            if 'bot_percentage' in df.columns:
                avg_bots = df['bot_percentage'].fillna(0).mean()
                if avg_bots > 60:
                    score += 35
                elif avg_bots > 40:
                    score += 25
                elif avg_bots > 25:
                    score += 15
            
            # –í—ã—Å–æ–∫–∞—è –∫–æ–Ω—Ü–µ–Ω—Ç—Ä–∞—Ü–∏—è —Ç–æ–ø-10 —Ö–æ–ª–¥–µ—Ä–æ–≤
            if 'top10_holders_percent' in df.columns:
                avg_top10 = df['top10_holders_percent'].fillna(0).mean()
                if avg_top10 > 70:
                    score += 30
                elif avg_top10 > 50:
                    score += 20
            
            # DEX –Ω–µ –æ–ø–ª–∞—á–µ–Ω (–∫—Ä–∞—Å–Ω—ã–π —Ñ–ª–∞–≥)
            if 'dex_paid' in df.columns:
                dex_paid_count = df['dex_paid'].fillna(False).sum()
                total_records = len(df)
                if dex_paid_count / total_records < 0.5:  # –ú–µ–Ω—å—à–µ 50% –∑–∞–ø–∏—Å–µ–π —Å –æ–ø–ª–∞—á–µ–Ω–Ω—ã–º DEX
                    score += 25
        
        return min(score, 100)  # –ú–∞–∫—Å–∏–º—É–º 100
    
    def create_token_report(self, token_address: str) -> Dict:
        """–°–æ–∑–¥–∞–µ—Ç –ø–æ–¥—Ä–æ–±–Ω—ã–π –æ—Ç—á–µ—Ç –ø–æ —Ç–æ–∫–µ–Ω—É"""
        df = self.load_token_data(token_address)
        
        if df.empty:
            return {'error': '–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞'}
        
        patterns = self.detect_volume_bot_patterns(df)
        risk_score = self.calculate_risk_score(patterns, df)
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        stats = {}
        
        if 'bundlers_percentage' in df.columns:
            stats['bundlers'] = {
                'avg': df['bundlers_percentage'].fillna(0).mean(),
                'max': df['bundlers_percentage'].fillna(0).max(),
                'min': df['bundlers_percentage'].fillna(0).min()
            }
        
        if 'holders_count' in df.columns:
            stats['holders'] = {
                'avg': df['holders_count'].fillna(0).mean(),
                'max': df['holders_count'].fillna(0).max(),
                'min': df['holders_count'].fillna(0).min(),
                'growth': df['holders_count'].fillna(0).iloc[-1] - df['holders_count'].fillna(0).iloc[0] if len(df) > 1 else 0
            }
        
        if 'liquidity_sol' in df.columns:
            stats['liquidity_sol'] = {
                'avg': df['liquidity_sol'].fillna(0).mean(),
                'max': df['liquidity_sol'].fillna(0).max(),
                'min': df['liquidity_sol'].fillna(0).min()
            }
        
        if 'bot_percentage' in df.columns:
            stats['bots'] = {
                'avg': df['bot_percentage'].fillna(0).mean(),
                'max': df['bot_percentage'].fillna(0).max(),
                'min': df['bot_percentage'].fillna(0).min()
            }
        
        if 'insiders_percentage' in df.columns:
            stats['insiders'] = {
                'avg': df['insiders_percentage'].fillna(0).mean(),
                'max': df['insiders_percentage'].fillna(0).max(),
                'min': df['insiders_percentage'].fillna(0).min()
            }
        
        if 'top10_holders_percent' in df.columns:
            stats['top10_holders'] = {
                'avg': df['top10_holders_percent'].fillna(0).mean(),
                'max': df['top10_holders_percent'].fillna(0).max(),
                'min': df['top10_holders_percent'].fillna(0).min()
            }
        
        if 'dex_paid' in df.columns:
            dex_paid_count = df['dex_paid'].fillna(False).sum()
            stats['dex_paid'] = {
                'total_records': len(df),
                'paid_count': int(dex_paid_count),
                'paid_percentage': (dex_paid_count / len(df)) * 100 if len(df) > 0 else 0
            }
        
        report = {
            'token_address': token_address,
            'analysis_timestamp': datetime.now().isoformat(),
            'data_points': len(df),
            'monitoring_duration': str(df['timestamp'].max() - df['timestamp'].min()) if len(df) > 1 else '0:00:00',
            'risk_score': risk_score,
            'risk_level': self.get_risk_level(risk_score),
            'suspicious_patterns': patterns,
            'statistics': stats,
            'recommendations': self.get_recommendations(risk_score, patterns)
        }
        
        return report
    
    def get_risk_level(self, score: float) -> str:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —É—Ä–æ–≤–µ–Ω—å —Ä–∏—Å–∫–∞"""
        if score >= 80:
            return "üî¥ –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô - –û—á–µ–Ω—å –≤—ã—Å–æ–∫–∞—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å volume bot marketing"
        elif score >= 60:
            return "üü† –í–´–°–û–ö–ò–ô - –ü–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω–∞—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å"
        elif score >= 40:
            return "üü° –°–†–ï–î–ù–ò–ô - –ù–µ–∫–æ—Ç–æ—Ä—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –º–∞–Ω–∏–ø—É–ª—è—Ü–∏–π"
        elif score >= 20:
            return "üü¢ –ù–ò–ó–ö–ò–ô - –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–µ –ø–æ–¥–æ–∑—Ä–µ–Ω–∏—è"
        else:
            return "‚úÖ –ù–û–†–ú–ê–õ–¨–ù–´–ô - –ù–µ—Ç –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –º–∞–Ω–∏–ø—É–ª—è—Ü–∏–π"
    
    def get_recommendations(self, score: float, patterns: Dict) -> List[str]:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏"""
        recommendations = []
        
        if score >= 60:
            recommendations.append("‚ùå –ù–ï –†–ï–ö–û–ú–ï–ù–î–£–ï–¢–°–Ø –∫ –∏–Ω–≤–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—é")
            recommendations.append("üîç –¢—Ä–µ–±—É–µ—Ç—Å—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ")
        
        if patterns['suspicious_bundler_spikes']:
            recommendations.append("‚ö†Ô∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã–µ —Å–∫–∞—á–∫–∏ –±–∞–Ω–¥–ª–µ—Ä–æ–≤")
        
        if patterns['whale_concentration']:
            recommendations.append("üêã –í—ã—Å–æ–∫–∞—è –∫–æ–Ω—Ü–µ–Ω—Ç—Ä–∞—Ü–∏—è —Å—Ä–µ–¥–∏ —Ç–æ–ø-10 —Ö–æ–ª–¥–µ—Ä–æ–≤")
        
        if patterns['coordinated_activity']:
            recommendations.append("ü§ñ –û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ –∫–æ–æ—Ä–¥–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –±–æ—Ç–æ–≤")
        
        if patterns['liquidity_manipulation']:
            recommendations.append("üíß –í–æ–∑–º–æ–∂–Ω—ã –º–∞–Ω–∏–ø—É–ª—è—Ü–∏–∏ —Å –ª–∏–∫–≤–∏–¥–Ω–æ—Å—Ç—å—é")
        
        if score < 40:
            recommendations.append("‚úÖ –¢–æ–∫–µ–Ω –≤—ã–≥–ª—è–¥–∏—Ç –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –±–µ–∑–æ–ø–∞—Å–Ω–æ")
        
        return recommendations
    
    def create_visualization(self, token_address: str):
        """–°–æ–∑–¥–∞–µ—Ç –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é –¥–∞–Ω–Ω—ã—Ö —Ç–æ–∫–µ–Ω–∞"""
        df = self.load_token_data(token_address)
        
        if df.empty:
            logger.warning(f"‚ö†Ô∏è –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ —Ç–æ–∫–µ–Ω–∞ {token_address[:8]}...")
            return
        
        # –°–æ–∑–¥–∞–µ–º —Ñ–∏–≥—É—Ä—É —Å –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ –≥—Ä–∞—Ñ–∏–∫–∞–º–∏
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        fig.suptitle(f'–ê–Ω–∞–ª–∏–∑ –ø–æ–≤–µ–¥–µ–Ω–∏—è —Ç–æ–∫–µ–Ω–∞ {token_address[:8]}...', fontsize=16)
        
        # –ì—Ä–∞—Ñ–∏–∫ 1: –ë–∞–Ω–¥–ª–µ—Ä—ã –∏ —Å–Ω–∞–π–ø–µ—Ä—ã
        if 'bundlers_percentage' in df.columns and 'snipers_percentage' in df.columns:
            axes[0, 0].plot(df['timestamp'], df['bundlers_percentage'].fillna(0), label='Bundlers %', color='red', linewidth=2)
            axes[0, 0].plot(df['timestamp'], df['snipers_percentage'].fillna(0), label='Snipers %', color='orange', linewidth=2)
            axes[0, 0].set_title('Bundlers –∏ Snipers %')
            axes[0, 0].set_ylabel('–ü—Ä–æ—Ü–µ–Ω—Ç')
            axes[0, 0].legend()
            axes[0, 0].grid(True, alpha=0.3)
        
        # –ì—Ä–∞—Ñ–∏–∫ 2: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ö–æ–ª–¥–µ—Ä–æ–≤
        if 'holders_count' in df.columns:
            axes[0, 1].plot(df['timestamp'], df['holders_count'].fillna(0), label='Holders', color='blue', linewidth=2)
            axes[0, 1].set_title('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ö–æ–ª–¥–µ—Ä–æ–≤')
            axes[0, 1].set_ylabel('–•–æ–ª–¥–µ—Ä—ã')
            axes[0, 1].grid(True, alpha=0.3)
        
        # –ì—Ä–∞—Ñ–∏–∫ 3: –õ–∏–∫–≤–∏–¥–Ω–æ—Å—Ç—å
        if 'liquidity_usd' in df.columns:
            axes[1, 0].plot(df['timestamp'], df['liquidity_usd'].fillna(0), label='Liquidity USD', color='green', linewidth=2)
            axes[1, 0].set_title('–õ–∏–∫–≤–∏–¥–Ω–æ—Å—Ç—å (USD)')
            axes[1, 0].set_ylabel('USD')
            axes[1, 0].grid(True, alpha=0.3)
        
        # –ì—Ä–∞—Ñ–∏–∫ 4: –ü—Ä–æ—Ü–µ–Ω—Ç —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–∞
        if 'dev_percentage' in df.columns:
            axes[1, 1].plot(df['timestamp'], df['dev_percentage'].fillna(0), label='Dev %', color='purple', linewidth=2)
            axes[1, 1].set_title('–ü—Ä–æ—Ü–µ–Ω—Ç —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–∞')
            axes[1, 1].set_ylabel('–ü—Ä–æ—Ü–µ–Ω—Ç')
            axes[1, 1].grid(True, alpha=0.3)
        
        # –ü–æ–≤–æ—Ä–∞—á–∏–≤–∞–µ–º –ø–æ–¥–ø–∏—Å–∏ –≤—Ä–µ–º–µ–Ω–∏
        for ax in axes.flat:
            ax.tick_params(axis='x', rotation=45)
        
        plt.tight_layout()
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≥—Ä–∞—Ñ–∏–∫
        output_path = self.analysis_dir / f"token_analysis_{token_address[:8]}.png"
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        logger.info(f"üìä –ì—Ä–∞—Ñ–∏–∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {output_path}")
    
    def analyze_all_tokens(self) -> pd.DataFrame:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –≤—Å–µ —Ç–æ–∫–µ–Ω—ã –∏ —Å–æ–∑–¥–∞–µ—Ç —Å–≤–æ–¥–Ω—ã–π –æ—Ç—á–µ—Ç"""
        if not self.data_dir.exists():
            logger.error("‚ùå –ü–∞–ø–∫–∞ —Å –¥–∞–Ω–Ω—ã–º–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
            return pd.DataFrame()
        
        token_dirs = [d for d in self.data_dir.iterdir() if d.is_dir()]
        
        if not token_dirs:
            logger.error("‚ùå –¢–æ–∫–µ–Ω—ã –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
            return pd.DataFrame()
        
        all_reports = []
        
        for token_dir in token_dirs:
            token_address = token_dir.name
            logger.info(f"üîç –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç–æ–∫–µ–Ω {token_address[:8]}...")
            
            try:
                report = self.create_token_report(token_address)
                
                if 'error' not in report:
                    # –°–æ–∑–¥–∞–µ–º –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é
                    self.create_visualization(token_address)
                    
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ–¥—Ä–æ–±–Ω—ã–π –æ—Ç—á–µ—Ç
                    report_path = self.analysis_dir / f"report_{token_address[:8]}.json"
                    with open(report_path, 'w', encoding='utf-8') as f:
                        json.dump(report, f, indent=2, ensure_ascii=False, default=str)
                    
                    # –î–æ–±–∞–≤–ª—è–µ–º –≤ —Å–≤–æ–¥–∫—É
                    summary = {
                        'token_address': token_address,
                        'risk_score': report['risk_score'],
                        'risk_level': report['risk_level'],
                        'data_points': report['data_points'],
                        'monitoring_duration': report['monitoring_duration'],
                        'bundler_spikes': len(report['suspicious_patterns']['suspicious_bundler_spikes']),
                        'liquidity_manipulations': len(report['suspicious_patterns']['liquidity_manipulation']),
                        'whale_concentrations': len(report['suspicious_patterns']['whale_concentration'])
                    }
                    
                    all_reports.append(summary)
                    
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —Ç–æ–∫–µ–Ω–∞ {token_address[:8]}...: {e}")
        
        # –°–æ–∑–¥–∞–µ–º —Å–≤–æ–¥–Ω—ã–π DataFrame
        summary_df = pd.DataFrame(all_reports)
        
        if not summary_df.empty:
            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —Ä–∏—Å–∫-—Å–∫–æ—Ä—É
            summary_df = summary_df.sort_values('risk_score', ascending=False)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–≤–æ–¥–Ω—ã–π –æ—Ç—á–µ—Ç
            summary_path = self.analysis_dir / "tokens_summary.csv"
            summary_df.to_csv(summary_path, index=False, encoding='utf-8')
            
            logger.info(f"üìã –°–≤–æ–¥–Ω—ã–π –æ—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {summary_path}")
            logger.info(f"üîç –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤: {len(summary_df)}")
            
            # –í—ã–≤–æ–¥–∏–º —Ç–æ–ø –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤
            logger.info("\nüö® –¢–û–ü –ü–û–î–û–ó–†–ò–¢–ï–õ–¨–ù–´–• –¢–û–ö–ï–ù–û–í:")
            for i, row in summary_df.head(5).iterrows():
                logger.info(f"  {row['token_address'][:8]}... - –†–∏—Å–∫: {row['risk_score']:.1f} - {row['risk_level']}")
        
        return summary_df

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    logger.info("üîç –ó–∞–ø—É—Å–∫ –∞–Ω–∞–ª–∏–∑–∞ –ø–æ–≤–µ–¥–µ–Ω–∏—è —Ç–æ–∫–µ–Ω–æ–≤...")
    
    analyzer = TokenBehaviorAnalyzer()
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –≤—Å–µ —Ç–æ–∫–µ–Ω—ã
    summary = analyzer.analyze_all_tokens()
    
    if not summary.empty:
        logger.info("‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ")
        logger.info(f"üìä –§–∞–π–ª—ã –∞–Ω–∞–ª–∏–∑–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –ø–∞–ø–∫—É: {analyzer.analysis_dir}")
    else:
        logger.warning("‚ö†Ô∏è –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")

if __name__ == "__main__":
    main() 