#!/usr/bin/env python3
"""
–ü—Ä–æ—Å—Ç–∞—è –∏ –Ω–∞–¥–µ–∂–Ω–∞—è –º—É–ª—å—Ç–∏–ø–æ—Ç–æ—á–Ω–∞—è –≤–µ—Ä—Å–∏—è test_filter.py
–§–æ–∫—É—Å –Ω–∞ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏ –∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –±–µ–∑ —Å–ª–æ–∂–Ω–æ–π –ª–æ–≥–∏–∫–∏.
"""

import os
import re
import logging
import threading
from datetime import datetime
from typing import List, Dict, Optional
import time
from concurrent.futures import ThreadPoolExecutor, as_completed
import multiprocessing

# Thread-safe —Å—á–µ—Ç—á–∏–∫–∏
class ThreadSafeCounters:
    def __init__(self):
        self._lock = threading.Lock()
        self.processed = 0
        self.successful = 0
        self.errors = 0
        self.would_send = 0
        self.would_reject = 0
        self.blacklisted = 0
        self.no_data = 0
        
    def increment_processed(self):
        with self._lock:
            self.processed += 1
    
    def increment_successful(self):
        with self._lock:
            self.successful += 1
    
    def increment_error(self):
        with self._lock:
            self.errors += 1
            
    def increment_would_send(self):
        with self._lock:
            self.would_send += 1
            
    def increment_would_reject(self):
        with self._lock:
            self.would_reject += 1
            
    def increment_blacklisted(self):
        with self._lock:
            self.blacklisted += 1
            
    def increment_no_data(self):
        with self._lock:
            self.no_data += 1
    
    def get_stats(self):
        with self._lock:
            return {
                'processed': self.processed,
                'successful': self.successful,
                'errors': self.errors,
                'would_send': self.would_send,
                'would_reject': self.would_reject,
                'blacklisted': self.blacklisted,
                'no_data': self.no_data
            }

# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ —Å—á–µ—Ç—á–∏–∫–∏
counters = ThreadSafeCounters()

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class SimpleTokenAnalyzer:
    """–ü—Ä–æ—Å—Ç–æ–π –º—É–ª—å—Ç–∏–ø–æ—Ç–æ—á–Ω—ã–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä —Ç–æ–∫–µ–Ω–æ–≤"""
    
    def __init__(self, max_workers: int = None):
        cpu_count = multiprocessing.cpu_count()
        self.max_workers = max_workers or min(cpu_count * 2, 16)  # –ù–µ –±–æ–ª–µ–µ 16 –ø–æ—Ç–æ–∫–æ–≤ –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
        
        # –ö–æ–º–ø–∏–ª–∏—Ä—É–µ–º regex –æ–¥–∏–Ω —Ä–∞–∑
        self.regex_patterns = {
            'holders': re.compile(r'üë• –•–æ–ª–¥–µ—Ä—ã: (\d+)'),
            'mcap': re.compile(r'üí∞ Market Cap: \$([0-9,.]+)'),
            'liquidity': re.compile(r'üíß –õ–∏–∫–≤–∏–¥–Ω–æ—Å—Ç—å: \$([0-9,]+)'),
            'snipers': re.compile(r'üéØ –°–Ω–∞–π–ø–µ—Ä—ã: ([0-9.]+)% \((\d+)\)'),
            'dev': re.compile(r'üë®‚Äçüíº Dev %: ([0-9.]+)%'),
            'insiders': re.compile(r'üë®‚Äçüíº –ò–Ω—Å–∞–π–¥–µ—Ä—ã: ([0-9.]+)%'),
            'bundlers': re.compile(r'üì¶ –ë–∞–Ω–¥–ª–µ—Ä—ã: (\d+) \(([0-9.]+)%\)'),
            'notification': re.compile(r'üì¢ –û—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ|notification sent', re.IGNORECASE)
        }
        
        logger.info(f"üöÄ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω –ø—Ä–æ—Å—Ç–æ–π –º—É–ª—å—Ç–∏–ø–æ—Ç–æ—á–Ω—ã–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä:")
        logger.info(f"   ‚Ä¢ –ü–æ—Ç–æ–∫–æ–≤: {self.max_workers}")
        logger.info(f"   ‚Ä¢ CPU —è–¥–µ—Ä: {cpu_count}")

    def analyze_single_token(self, log_path: str) -> Dict:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –æ–¥–∏–Ω —Ç–æ–∫–µ–Ω"""
        token_id = os.path.basename(log_path).replace('.log', '')
        thread_name = threading.current_thread().name
        
        try:
            counters.increment_processed()
            
            # –°–æ–±–∏—Ä–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏ –∏–∑ —Ñ–∞–π–ª–∞
            metrics = self.extract_metrics_from_log(log_path)
            
            if not metrics:
                counters.increment_no_data()
                return {
                    'token_id': token_id,
                    'decision': 'NO_DATA',
                    'reason': '–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö',
                    'thread': thread_name
                }
            
            # –ü—Ä–æ—Å—Ç–∞—è –ª–æ–≥–∏–∫–∞ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ (–æ—Å–Ω–æ–≤–Ω—ã–µ –∫—Ä–∏—Ç–µ—Ä–∏–∏)
            decision_result = self.make_decision(metrics, token_id)
            decision_result['thread'] = thread_name
            
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—á–µ—Ç—á–∏–∫–∏
            decision = decision_result.get('decision')
            if decision == 'WOULD_SEND':
                counters.increment_would_send()
            elif decision == 'WOULD_REJECT':
                counters.increment_would_reject()
            elif decision == 'BLACKLISTED':
                counters.increment_blacklisted()
            else:
                counters.increment_no_data()
                
            counters.increment_successful()
            return decision_result
            
        except Exception as e:
            counters.increment_error()
            logger.error(f"üí• [{thread_name}] –û—à–∏–±–∫–∞ –¥–ª—è {token_id}: {e}")
            return {
                'token_id': token_id,
                'decision': 'ERROR',
                'reason': f'–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞: {str(e)}',
                'thread': thread_name
            }

    def extract_metrics_from_log(self, log_path: str) -> Optional[Dict]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ –∏–∑ –ª–æ–≥-—Ñ–∞–π–ª–∞"""
        metrics = {}
        
        try:
            with open(log_path, 'r', encoding='utf-8', buffering=8192) as f:
                for line in f:
                    # –†–∞–Ω–Ω–∏–π –≤—ã—Ö–æ–¥ –µ—Å–ª–∏ –Ω–∞–π–¥–µ–Ω–æ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ
                    if self.regex_patterns['notification'].search(line):
                        break
                    
                    # –ò—â–µ–º –º–µ—Ç—Ä–∏–∫–∏
                    if 'üë• –•–æ–ª–¥–µ—Ä—ã:' in line:
                        match = self.regex_patterns['holders'].search(line)
                        if match:
                            metrics['holders'] = int(match.group(1))
                    
                    elif 'üí∞ Market Cap:' in line:
                        match = self.regex_patterns['mcap'].search(line)
                        if match:
                            try:
                                mcap_str = match.group(1).replace(',', '')
                                metrics['market_cap'] = float(mcap_str)
                            except ValueError:
                                pass
                    
                    elif 'üíß –õ–∏–∫–≤–∏–¥–Ω–æ—Å—Ç—å:' in line:
                        match = self.regex_patterns['liquidity'].search(line)
                        if match:
                            try:
                                liquidity_str = match.group(1).replace(',', '')
                                metrics['liquidity'] = float(liquidity_str)
                            except ValueError:
                                pass
                    
                    elif 'üéØ –°–Ω–∞–π–ø–µ—Ä—ã:' in line:
                        match = self.regex_patterns['snipers'].search(line)
                        if match:
                            try:
                                metrics['snipers_percent'] = float(match.group(1))
                                metrics['snipers_count'] = int(match.group(2))
                            except ValueError:
                                pass
                    
                    elif 'üë®‚Äçüíº Dev %:' in line:
                        match = self.regex_patterns['dev'].search(line)
                        if match:
                            try:
                                metrics['dev_percent'] = float(match.group(1))
                            except ValueError:
                                pass
                    
                    elif 'üë®‚Äçüíº –ò–Ω—Å–∞–π–¥–µ—Ä—ã:' in line:
                        match = self.regex_patterns['insiders'].search(line)
                        if match:
                            try:
                                metrics['insiders_percent'] = float(match.group(1))
                            except ValueError:
                                pass
                    
                    elif 'üì¶ –ë–∞–Ω–¥–ª–µ—Ä—ã:' in line:
                        match = self.regex_patterns['bundlers'].search(line)
                        if match:
                            try:
                                metrics['bundlers_count'] = int(match.group(1))
                                metrics['bundlers_percent'] = float(match.group(2))
                            except ValueError:
                                pass
        
        except Exception as e:
            logger.debug(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è {log_path}: {e}")
            return None
        
        return metrics if metrics else None

    def make_decision(self, metrics: Dict, token_id: str) -> Dict:
        """–ü—Ä–∏–Ω–∏–º–∞–µ—Ç —Ä–µ—à–µ–Ω–∏–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ –º–µ—Ç—Ä–∏–∫"""
        
        # –ë–∞–∑–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
        holders = metrics.get('holders', 0)
        liquidity = metrics.get('liquidity', 0)
        dev_percent = metrics.get('dev_percent', 0)
        snipers_percent = metrics.get('snipers_percent', 0)
        snipers_count = metrics.get('snipers_count', 0)
        insiders_percent = metrics.get('insiders_percent', 0)
        market_cap = metrics.get('market_cap', 0)
        
        # –ü—Ä–æ—Å—Ç—ã–µ –∫—Ä–∏—Ç–µ—Ä–∏–∏ –¥–ª—è ACTIVITY —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π
        reasons = []
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ö–æ–ª–¥–µ—Ä–æ–≤
        if holders < 30:
            reasons.append(f"–ú–∞–ª–æ —Ö–æ–ª–¥–µ—Ä–æ–≤ ({holders} < 30)")
        elif holders > 130:
            reasons.append(f"–ú–Ω–æ–≥–æ —Ö–æ–ª–¥–µ—Ä–æ–≤ ({holders} > 130)")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ª–∏–∫–≤–∏–¥–Ω–æ—Å—Ç–∏
        if liquidity < 10000:
            reasons.append(f"–ú–∞–ª–∞ –ª–∏–∫–≤–∏–¥–Ω–æ—Å—Ç—å (${liquidity:,.0f} < $10,000)")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ dev –ø—Ä–æ—Ü–µ–Ω—Ç–∞
        if dev_percent > 2:
            reasons.append(f"–í—ã—Å–æ–∫–∏–π dev –ø—Ä–æ—Ü–µ–Ω—Ç ({dev_percent:.1f}% > 2%)")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–Ω–∞–π–ø–µ—Ä–æ–≤
        if snipers_count > 20:
            reasons.append(f"–ú–Ω–æ–≥–æ —Å–Ω–∞–π–ø–µ—Ä–æ–≤ ({snipers_count} > 20)")
        elif snipers_percent > 5.0:
            reasons.append(f"–í—ã—Å–æ–∫–∏–π –ø—Ä–æ—Ü–µ–Ω—Ç —Å–Ω–∞–π–ø–µ—Ä–æ–≤ ({snipers_percent:.1f}% > 5%)")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏–Ω—Å–∞–π–¥–µ—Ä–æ–≤
        if insiders_percent > 22.0:
            reasons.append(f"–í—ã—Å–æ–∫–∏–π –ø—Ä–æ—Ü–µ–Ω—Ç –∏–Ω—Å–∞–π–¥–µ—Ä–æ–≤ ({insiders_percent:.1f}% > 22%)")
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        result = {
            'token_id': token_id,
            'holders': holders,
            'market_cap': market_cap,
            'liquidity': liquidity,
            'dev_percent': dev_percent,
            'snipers_percent': snipers_percent,
            'snipers_count': snipers_count,
            'insiders_percent': insiders_percent
        }
        
        if reasons:
            result.update({
                'decision': 'WOULD_REJECT',
                'reason': '; '.join(reasons[:2]),  # –ü–µ—Ä–≤—ã–µ 2 –ø—Ä–∏—á–∏–Ω—ã
                'notification_type': 'ACTIVITY'
            })
        else:
            result.update({
                'decision': 'WOULD_SEND',
                'reason': '–°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –≤—Å–µ–º –∫—Ä–∏—Ç–µ—Ä–∏—è–º activity —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è',
                'notification_type': 'ACTIVITY'
            })
        
        return result

    def analyze_all_tokens(self, tokens_logs_dir: str) -> List[Dict]:
        """–ú—É–ª—å—Ç–∏–ø–æ—Ç–æ—á–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –≤—Å–µ—Ö —Ç–æ–∫–µ–Ω–æ–≤"""
        if not os.path.exists(tokens_logs_dir):
            logger.error(f"‚ùå –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è {tokens_logs_dir} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
            return []
        
        log_files = [f for f in os.listdir(tokens_logs_dir) if f.endswith('.log')]
        
        if not log_files:
            logger.error(f"‚ùå –í –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ {tokens_logs_dir} –Ω–µ—Ç .log —Ñ–∞–π–ª–æ–≤")
            return []
        
        log_paths = [os.path.join(tokens_logs_dir, f) for f in log_files]
        
        logger.info(f"üöÄ –ü–†–û–°–¢–û–ô –ú–£–õ–¨–¢–ò–ü–û–¢–û–ß–ù–´–ô –ê–ù–ê–õ–ò–ó: {len(log_paths)} —Ç–æ–∫–µ–Ω–æ–≤")
        logger.info(f"‚ö° –ò—Å–ø–æ–ª—å–∑—É–µ–º {self.max_workers} –ø–æ—Ç–æ–∫–æ–≤")
        
        start_time = time.time()
        results = []
        
        with ThreadPoolExecutor(max_workers=self.max_workers, thread_name_prefix="token") as executor:
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–¥–∞—á–∏
            future_to_path = {executor.submit(self.analyze_single_token, path): path for path in log_paths}
            
            # –°–æ–±–∏—Ä–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            completed_count = 0
            for future in as_completed(future_to_path):
                try:
                    result = future.result(timeout=120)  # 2 –º–∏–Ω—É—Ç—ã –Ω–∞ —Ç–æ–∫–µ–Ω
                    results.append(result)
                    completed_count += 1
                    
                    # –ü—Ä–æ–≥—Ä–µ—Å—Å –∫–∞–∂–¥—ã–µ 25 —Ç–æ–∫–µ–Ω–æ–≤
                    if completed_count % 25 == 0:
                        elapsed = time.time() - start_time
                        speed = completed_count / elapsed if elapsed > 0 else 0
                        eta = (len(log_paths) - completed_count) / speed if speed > 0 else 0
                        
                        stats = counters.get_stats()
                        logger.info(f"‚ö° –ü—Ä–æ–≥—Ä–µ—Å—Å: {completed_count}/{len(log_paths)} "
                                  f"({speed:.1f} —Ç–æ–∫/—Å–µ–∫, ETA: {eta/60:.1f} –º–∏–Ω) "
                                  f"[‚úÖ{stats['successful']} ‚ùå{stats['errors']}]")
                        
                except Exception as e:
                    path = future_to_path[future]
                    token_id = os.path.basename(path).replace('.log', '')
                    logger.error(f"üí• Timeout/–æ—à–∏–±–∫–∞ –¥–ª—è {token_id}: {e}")
                    
                    error_result = {
                        'token_id': token_id,
                        'decision': 'ERROR',
                        'reason': f'Timeout: {str(e)}'
                    }
                    results.append(error_result)
                    counters.increment_error()
                    completed_count += 1
        
        total_time = time.time() - start_time
        final_speed = len(results) / total_time if total_time > 0 else 0
        
        logger.info(f"üéØ –ü–†–û–°–¢–û–ô –ú–£–õ–¨–¢–ò–ü–û–¢–û–ß–ù–´–ô –ê–ù–ê–õ–ò–ó –ó–ê–í–ï–†–®–ï–ù!")
        logger.info(f"‚è±Ô∏è –í—Ä–µ–º—è: {total_time:.1f} —Å–µ–∫")
        logger.info(f"‚ö° –°–∫–æ—Ä–æ—Å—Ç—å: {final_speed:.1f} —Ç–æ–∫–µ–Ω–æ–≤/—Å–µ–∫")
        
        return results

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    analyzer = SimpleTokenAnalyzer()
    
    logger.info("üöÄ –ü–†–û–°–¢–û–ô –ú–£–õ–¨–¢–ò–ü–û–¢–û–ß–ù–´–ô –ê–ù–ê–õ–ò–ó ACTIVITY –£–í–ï–î–û–ú–õ–ï–ù–ò–ô")
    tokens_logs_dir = '/home/creatxr/solspider/tokens_logs'
    
    start_time = time.time()
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –≤—Å–µ —Ç–æ–∫–µ–Ω—ã
    results = analyzer.analyze_all_tokens(tokens_logs_dir)
    
    if not results:
        logger.error("‚ùå –ù–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
        return
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    stats = counters.get_stats()
    total_time = time.time() - start_time
    final_speed = len(results) / total_time if total_time > 0 else 0
    
    logger.info(f"\nüìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê - {len(results)} —Ç–æ–∫–µ–Ω–æ–≤:")
    logger.info(f"üöÄ WOULD_SEND: {stats['would_send']} ({stats['would_send']/len(results)*100:.1f}%)")
    logger.info(f"‚ùå WOULD_REJECT: {stats['would_reject']} ({stats['would_reject']/len(results)*100:.1f}%)")
    logger.info(f"‚ö´ BLACKLISTED: {stats['blacklisted']} ({stats['blacklisted']/len(results)*100:.1f}%)")
    logger.info(f"üí• ERRORS: {stats['errors']} ({stats['errors']/len(results)*100:.1f}%)")
    logger.info(f"üìä NO_DATA: {stats['no_data']} ({stats['no_data']/len(results)*100:.1f}%)")
    
    logger.info(f"\n‚ö° –ü–†–û–ò–ó–í–û–î–ò–¢–ï–õ–¨–ù–û–°–¢–¨:")
    logger.info(f"   ‚Ä¢ –í—Ä–µ–º—è: {total_time:.1f} —Å–µ–∫")
    logger.info(f"   ‚Ä¢ –°–∫–æ—Ä–æ—Å—Ç—å: {final_speed:.1f} —Ç–æ–∫–µ–Ω–æ–≤/—Å–µ–∫")
    logger.info(f"   ‚Ä¢ –£—Å–ø–µ—à–Ω—ã—Ö: {stats['successful']}")
    logger.info(f"   ‚Ä¢ –û—à–∏–±–æ–∫: {stats['errors']}")
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–∏–º–µ—Ä—ã –ø—Ä–æ—à–µ–¥—à–∏—Ö —Ç–æ–∫–µ–Ω–æ–≤
    passed_tokens = [r for r in results if r.get('decision') == 'WOULD_SEND']
    if passed_tokens:
        logger.info(f"\nüöÄ –ü–†–ò–ú–ï–†–´ –ü–†–û–®–ï–î–®–ò–• –¢–û–ö–ï–ù–û–í:")
        for example in passed_tokens[:5]:
            logger.info(f"   ‚Ä¢ {example['token_id']}: "
                       f"HOLDERS={example.get('holders', '?')}, "
                       f"LIQ=${example.get('liquidity', 0):,.0f}, "
                       f"SNIPERS={example.get('snipers_percent', 0):.1f}%")
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–∏—á–∏–Ω—ã –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è
    rejected_tokens = [r for r in results if r.get('decision') == 'WOULD_REJECT']
    if rejected_tokens:
        logger.info(f"\n‚ùå –ü–†–ò–ú–ï–†–´ –û–¢–ö–õ–û–ù–ï–ù–ù–´–• –¢–û–ö–ï–ù–û–í:")
        for example in rejected_tokens[:5]:
            logger.info(f"   ‚Ä¢ {example['token_id']}: {example.get('reason', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –ø—Ä–∏—á–∏–Ω–∞')}")

if __name__ == "__main__":
    main()
