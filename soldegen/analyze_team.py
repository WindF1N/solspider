import pandas as pd
import numpy as np
import os
import asyncio
from collections import defaultdict
import configparser
import json
from tqdm import tqdm
import bullx_client # bullx_client.py –ù–ï –ú–ï–ù–Ø–ï–ú, –æ–Ω —É–∂–µ –≥–æ—Ç–æ–≤

CONFIG_FILE = 'config.ini'
TEAMS_DIR = 'output/teams'
CACHE_FILE = 'output/launch_cache.json' # <<< –ü–£–¢–¨ –ö –ù–ê–®–ï–ú–£ –ö–≠–®–£
TARGET_TEAM = 'team_1'

def load_config():
    config = configparser.ConfigParser()
    if not config.read(CONFIG_FILE): raise FileNotFoundError(f"–§–∞–π–ª '{CONFIG_FILE}' –Ω–µ –Ω–∞–π–¥–µ–Ω.")
    return { 'entry_signal_wallets': config.getint('TeamAnalysisSettings', 'entry_signal_wallets'), 'safe_entry_window_minutes': config.getint('TeamAnalysisSettings', 'safe_entry_window_minutes'), }

def load_team_data(team_name):
    team_dir = os.path.join(TEAMS_DIR, team_name);
    if not os.path.exists(team_dir): raise FileNotFoundError(f"–ü–∞–ø–∫–∞ –¥–ª—è –∫–æ–º–∞–Ω–¥—ã {team_name} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞.")
    with open(os.path.join(team_dir, 'wallets.txt'), 'r') as f: wallets = {line.strip() for line in f if line.strip()}
    with open(os.path.join(team_dir, 'linking_tokens.txt'), 'r') as f: tokens = {line.strip() for line in f if line.strip()}
    print(f"üî¨ –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é –∫–æ–º–∞–Ω–¥—É '{team_name}': {len(wallets)} –∫–æ—à–µ–ª—å–∫–æ–≤, {len(tokens)} —Ç–æ–∫–µ–Ω–æ–≤-—É–ª–∏–∫.")
    return wallets, list(tokens)

def load_launch_cache(tokens_to_find):
    if not os.path.exists(CACHE_FILE): raise FileNotFoundError(f"–§–∞–π–ª –∫—ç—à–∞ {CACHE_FILE} –Ω–µ –Ω–∞–π–¥–µ–Ω. –°–Ω–∞—á–∞–ª–∞ –∑–∞–ø—É—Å—Ç–∏—Ç–µ cluster.py")
    with open(CACHE_FILE, 'r') as f:
        full_cache = json.load(f)
    
    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–æ–ª—å–∫–æ –Ω—É–∂–Ω—ã–µ –Ω–∞–º timestamp'—ã
    return {token: ts for token, ts in full_cache.items() if token in tokens_to_find}

def analyze_token_performance(price_df, t0_timestamp, config):
    if price_df.empty: return {}
    
    t0 = pd.to_datetime(t0_timestamp, unit='s', utc=True)
    
    # –ó–ê–ì–õ–£–®–ö–ê –î–õ–Ø –ê–ì–†–ï–°–°–ò–í–ù–û–ì–û –í–•–û–î–ê. –ù–∞–º –≤—Å–µ –µ—â–µ –Ω—É–∂–Ω—ã —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏ –¥–ª—è —ç—Ç–æ–≥–æ.
    # –ü–æ–∫–∞ —á—Ç–æ –º—ã –º–æ–∂–µ–º –ø–æ—Å—á–∏—Ç–∞—Ç—å —Ç–æ–ª—å–∫–æ "—Ç–µ—Ä–ø–µ–ª–∏–≤—ã–π" —Ö–∏—Ç—Ä–µ–π—Ç.
    aggressive_entry_price = np.nan 

    safe_window_start = t0 + pd.Timedelta(minutes=config['safe_entry_window_minutes'])
    safe_window_end = safe_window_start + pd.Timedelta(minutes=8)
    safe_window_prices = price_df[(price_df.index >= safe_window_start) & (price_df.index <= safe_window_end)]
    patient_entry_price = safe_window_prices['price'].median() if not safe_window_prices.empty else np.nan
    
    results = {}
    if not pd.isna(patient_entry_price):
        peak_price_after = price_df[price_df.index >= safe_window_start]['price'].max()
        multiplier = peak_price_after / patient_entry_price if patient_entry_price > 0 else 0
        results['pat_x2_hit'] = multiplier >= 2; results['pat_peak'] = multiplier
    return results

async def main():
    config = load_config()
    team_wallets, tokens = load_team_data(TARGET_TEAM)

    # --- –®–∞–≥ 1: –ó–∞–≥—Ä—É–∂–∞–µ–º –≤—Ä–µ–º—è —Å—Ç–∞—Ä—Ç–∞ –∏–∑ –∫—ç—à–∞ ---
    tokens_with_start_time = load_launch_cache(tokens)
    print(f"üïí –ò–∑ –∫—ç—à–∞ –∑–∞–≥—Ä—É–∂–µ–Ω–æ –≤—Ä–µ–º—è –∑–∞–ø—É—Å–∫–∞ –¥–ª—è {len(tokens_with_start_time)} —Ç–æ–∫–µ–Ω–æ–≤.")
    if not tokens_with_start_time: return

    # --- –®–∞–≥ 2: –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º —Ç–æ—á–Ω—ã–µ –≥—Ä–∞—Ñ–∏–∫–∏ –≤ BullX ---
    price_fetcher = bullx_client.PriceHistoryFetcher()
    price_histories = await price_fetcher.fetch_all_precise(tokens_with_start_time)
    await price_fetcher.close()
    if not price_histories: print("\n‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –Ω–∏ –æ–¥–Ω–æ–≥–æ –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –≥—Ä–∞—Ñ–∏–∫–∞."); return

    performance_results = []
    print("\n" + "="*50)
    for token, price_df in tqdm(price_histories.items(), desc="–ê–Ω–∞–ª–∏–∑ —Ç–æ–∫–µ–Ω–æ–≤"):
        # –ü–µ—Ä–µ–¥–∞–µ–º timestamp –∏–∑ –∫—ç—à–∞
        result = analyze_token_performance(price_df, tokens_with_start_time[token], config)
        performance_results.append(result)

    total_tokens = len(performance_results)
    if total_tokens == 0: print("\n–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –Ω–∏ –æ–¥–Ω–æ–≥–æ —Ç–æ–∫–µ–Ω–∞."); return
    
    pat_x2 = sum(1 for r in performance_results if r.get('pat_x2_hit'))
    avg_pat_peak = np.mean([r.get('pat_peak', 0) for r in performance_results if 'pat_peak' in r])
    
    team_dir = os.path.join(TEAMS_DIR, TARGET_TEAM)
    report_lines = [
        f"--- –ê–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏–π –æ—Ç—á–µ—Ç –ø–æ –ö–æ–º–∞–Ω–¥–µ: {TARGET_TEAM} ---",
        f"\n[–ê–Ω–∞–ª–∏–∑ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –Ω–∞ {total_tokens} —Ç–æ–∫–µ–Ω–∞—Ö]",
        f"\n--- üßò –¢–ï–†–ü–ï–õ–ò–í–ê–Ø –°–¢–†–ê–¢–ï–ì–ò–Ø (–≤—Ö–æ–¥ –ø–æ—Å–ª–µ {config['safe_entry_window_minutes']} –º–∏–Ω —Ö–∞–æ—Å–∞) ---",
        f"–•–∏—Ç—Ä–µ–π—Ç x2: {pat_x2}/{total_tokens} ({pat_x2/total_tokens:.1% if total_tokens > 0 else 0})",
        f"–°—Ä–µ–¥–Ω–∏–π –ø–∏–∫–æ–≤—ã–π –º–Ω–æ–∂–∏—Ç–µ–ª—å: x{avg_pat_peak:.2f}",
        "\n[–ê–Ω–∞–ª–∏–∑ —Ä–æ–ª–µ–π –∏ –∞–≥—Ä–µ—Å—Å–∏–≤–Ω–æ–π —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –±—É–¥–µ—Ç –¥–æ–±–∞–≤–ª–µ–Ω –≤ —Å–ª–µ–¥. –º–æ–¥—É–ª–µ]",
    ]
    report_path = os.path.join(team_dir, 'analysis_report.txt')
    with open(report_path, 'w') as f: f.write('\n'.join(report_lines))
    print("\n" + "\n".join(report_lines))
    print(f"\n‚úÖ –û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤: {report_path}")

if __name__ == "__main__":
    asyncio.run(main())